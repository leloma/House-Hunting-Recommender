{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9x94Ckz-djM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from lxml import html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Scraper Code"
      ],
      "metadata": {
        "id": "vYo3IBNjxW2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Beautiful Soup object\n",
        "soup = BeautifulSoup(salepage.text, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "# Find all div elements with the specified class\n",
        "divs = soup.find_all('div', class_='pull-left sc_listingTileContent')\n",
        "count = 1\n",
        "# Display the found divs\n",
        "for div in divs:\n",
        "    link_tag = div.find('a')\n",
        "    if link_tag:\n",
        "        propertyurl = \"https://www.property24.co.ke\" + link_tag['href']\n",
        "        response = requests.get(property_url)\n",
        "        property_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        description_div = property_soup.find('div', class_='sc_listingDetailsText')\n",
        "        if description_div:\n",
        "          description = description_div.get_text().strip()\n",
        "          print(\"Description:\", description)\n",
        "        else:\n",
        "          description = \"No description found for this property\"\n",
        "    else:\n",
        "        propertyurl = None\n",
        "    title = div.a['title']\n",
        "    price_div = div.find('div', class_='sc_listingTilePrice')\n",
        "    if price_div:\n",
        "        price_spans = price_div.find_all('span')\n",
        "        if len(price_spans) > 1:\n",
        "            from_price = price_spans[1].text.strip()\n",
        "            to_price = price_spans[3].text.strip()\n",
        "            price = f\"From {from_price} to {to_price}\"\n",
        "        else:\n",
        "            price = price_spans[0].text.strip()\n",
        "    else:\n",
        "        price = None\n",
        "\n",
        "    address = div.find('div', class_='sc_listingTileAddress').text.strip()\n",
        "    teaser_div = div.find('div', class_='sc_listingTileTeaser')\n",
        "    image_source = None\n",
        "    if teaser_div.a and teaser_div.a.img:\n",
        "        image_source = teaser_div.a.img['src']\n",
        "    description = teaser_div.text.strip()  # Extract the entire description directly\n",
        "\n",
        "    bed_img = div.find('img', class_='property24generic_icon_beds')\n",
        "    baths_img = div.find('img', class_='property24generic_icon_baths')\n",
        "    parking_img = div.find('img', class_='property24generic_icon_parking')\n",
        "\n",
        "    beds = bed_img.find_next('span').get_text() if bed_img else \"\"\n",
        "    baths = baths_img.find_next('span').get_text() if baths_img else \"\"\n",
        "    parking = parking_img.find_next('span').get_text() if parking_img else \"\"\n",
        "\n",
        "    # image_link = div.find('img', class_='pull-left')['src'] if div.find('img', class_='pull-left') else None\n",
        "\n",
        "    print(\"Property URL:\", propertyurl)\n",
        "    print(\"Title:\", title)\n",
        "    print(\"Price:\", price)\n",
        "    print(\"Image Source:\", image_source)\n",
        "    print(\"Address:\", address)\n",
        "    print(\"Description:\", description)\n",
        "    print(\"Bedrooms:\", beds)\n",
        "    print(\"Bathrooms:\", baths)\n",
        "    print(\"Parking spaces:\", parking)\n",
        "    # print(\"Image Link:\", image_link)\n",
        "    imgs = div.find_all('img')\n",
        "    for img in imgs:\n",
        "        if 'src' in img.attrs:\n",
        "            print(\"Image Link:\", img['src'])\n",
        "            break  # Break after finding the first image\n",
        "    print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "uzBkybsHToG0",
        "outputId": "b9fad04e-bf77-4351-d4e7-26edb42f20ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'salepage' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d454f9d6b56b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a Beautiful Soup object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalepage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'salepage' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kenya Property24 For Sale"
      ],
      "metadata": {
        "id": "dIwwtq3Zxj_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "for_sale_url = 'https://www.property24.co.ke/property-for-sale?provinceids=83,96,93,76,79,66,101,80,76,86&cityids=1890,1848,1847,1850,1868,1899,1901,2149'\n",
        "salepage = requests.get(for_sale_url)\n",
        "soup = BeautifulSoup(salepage.text, 'html.parser')\n",
        "\n",
        "# Initialize an empty dataframe\n",
        "data = {'Property URL': [], 'Title': [], 'Type': [], 'Price': [], 'Address': [], 'Description': [],\n",
        "        'Bedrooms': [], 'Bathrooms': [], 'Parking spaces': [],\n",
        "        'Floor Size': [], 'Erf Size': [], }\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Get data from all pages inside pagination\n",
        "def getnextpage(soup):\n",
        "  page = soup.find('div', {'class': 'text-center'})\n",
        "  if not page.find('span', {'class': 'pull-right text-muted'}).find('a'):\n",
        "    return  # If there's no span with the specified class containing an 'a' tag, end the search\n",
        "  else:\n",
        "    for_sale_url = page.find('span', {'class': 'pull-right text-muted'}).find('a')['href']\n",
        "    return for_sale_url\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "  print(for_sale_url)\n",
        "  for_sale_url = getnextpage(soup)\n",
        "  if not for_sale_url:\n",
        "    break\n",
        "  salepage = requests.get(for_sale_url)\n",
        "  soup = BeautifulSoup(salepage.text, 'html.parser')\n",
        "  # Find all div elements with the specified class\n",
        "  divs = soup.find_all('div', class_='pull-left sc_listingTileContent')\n",
        "  count = 1\n",
        "  # Display the found divs\n",
        "  for div in divs:\n",
        "      link_tag = div.find('a')\n",
        "      if link_tag:\n",
        "        propertyurl = \"https://www.property24.co.ke\" + link_tag['href']\n",
        "        property_response = requests.get(propertyurl)\n",
        "        property_soup = BeautifulSoup(property_response.text, 'html.parser')\n",
        "\n",
        "        description_div = property_soup.find('div', class_='sc_listingDetailsText')\n",
        "        if description_div:\n",
        "          description = description_div.get_text().strip()\n",
        "\n",
        "        else:\n",
        "          description = \"No description found for this property\"\n",
        "      else:\n",
        "          propertyurl = None\n",
        "      title = div.a['title']\n",
        "      price_div = div.find('div', class_='sc_listingTilePrice')\n",
        "      if price_div:\n",
        "          price_spans = price_div.find_all('span')\n",
        "          if len(price_spans) > 1:\n",
        "              from_price = price_spans[1].text.strip()\n",
        "              to_price = price_spans[3].text.strip()\n",
        "              price = f\"From {from_price} to {to_price}\"\n",
        "          else:\n",
        "              price = price_spans[0].text.strip()\n",
        "      else:\n",
        "          price = None\n",
        "\n",
        "      address = div.find('div', class_='sc_listingTileAddress').text.strip()\n",
        "      bed_img = div.find('img', class_='property24generic_icon_beds')\n",
        "      baths_img = div.find('img', class_='property24generic_icon_baths')\n",
        "      parking_img = div.find('img', class_='property24generic_icon_parking')\n",
        "\n",
        "      beds = bed_img.find_next('span').get_text() if bed_img else \"\"\n",
        "      baths = baths_img.find_next('span').get_text() if baths_img else \"\"\n",
        "      parking = parking_img.find_next('span').get_text() if parking_img else \"\"\n",
        "\n",
        "      floor_unit = \"\"\n",
        "      erf_unit = \"\"\n",
        "      floor_size = \"\"\n",
        "      erf_size = \"\"\n",
        "\n",
        "      floor_size_span = div.find('span', class_='sc_erfSize')\n",
        "      if floor_size_span:\n",
        "          text = floor_size_span.get_text()\n",
        "          if 'Floor Size' in text:\n",
        "              floor_size = floor_size_span.find('span').get_text().strip()\n",
        "              floor_unit = floor_size_span.contents[-1].strip()\n",
        "          elif 'Erf Size' in text:\n",
        "              erf_size = floor_size_span.find('span').get_text().strip()\n",
        "              erf_unit = floor_size_span.contents[-1].strip()\n",
        "\n",
        "      property_data = {\n",
        "        'Property URL': propertyurl,\n",
        "        'Title': title,\n",
        "        'Type' : \"For Sale\",\n",
        "        'Price': price,\n",
        "        'Address': address,\n",
        "        'Description': description,\n",
        "        'Bedrooms': beds,\n",
        "        'Bathrooms': baths,\n",
        "        'Parking spaces': parking,\n",
        "        'Floor Size': floor_size + ' ' + floor_unit,\n",
        "        'Erf Size': erf_size + ' ' + erf_unit,\n",
        "    }\n",
        "\n",
        "      # Append the data to the DataFrame\n",
        "      df = pd.concat([df, pd.DataFrame([property_data])], ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "0gxEkdjMToKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()\n"
      ],
      "metadata": {
        "id": "h_tkLTyhr24Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kenya Property 24 For Rent"
      ],
      "metadata": {
        "id": "_mECiJsDxs0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_rent_url = 'https://www.property24.co.ke/property-to-rent?provinceids=83,96,93,76,79,66,101,80,76,86&cityids=1890,1848,1847,1850,1868,1899,1901,2149'\n",
        "rentpage = requests.get(to_rent_url)\n",
        "soup = BeautifulSoup(rentpage.text, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "# Get data from all pages inside pagination\n",
        "def getnextpage(soup):\n",
        "  page = soup.find('div', {'class': 'text-center'})\n",
        "  if not page.find('span', {'class': 'pull-right text-muted'}).find('a'):\n",
        "    return  # If there's no span with the specified class containing an 'a' tag, end the search\n",
        "  else:\n",
        "    to_rent_url = page.find('span', {'class': 'pull-right text-muted'}).find('a')['href']\n",
        "    return to_rent_url\n",
        "\n",
        "property_data_list = []\n",
        "\n",
        "while True:\n",
        "  print(to_rent_url)\n",
        "  to_rent_url = getnextpage(soup)\n",
        "  if not to_rent_url:\n",
        "    break\n",
        "  rentpage = requests.get(to_rent_url)\n",
        "  soup = BeautifulSoup(rentpage.text, 'html.parser')\n",
        "  # Find all div elements with the specified class\n",
        "  divs = soup.find_all('div', class_='pull-left sc_listingTileContent')\n",
        "  count = 1\n",
        "  # Display the found divs\n",
        "  for div in divs:\n",
        "      link_tag = div.find('a')\n",
        "      if link_tag:\n",
        "        propertyurl = \"https://www.property24.co.ke\" + link_tag['href']\n",
        "        property_response = requests.get(propertyurl)\n",
        "        property_soup = BeautifulSoup(property_response.text, 'html.parser')\n",
        "\n",
        "        description_div = property_soup.find('div', class_='sc_listingDetailsText')\n",
        "        if description_div:\n",
        "          description = description_div.get_text().strip()\n",
        "\n",
        "        else:\n",
        "          description = \"No description found for this property\"\n",
        "      else:\n",
        "          propertyurl = None\n",
        "      title = div.a['title']\n",
        "      # price_div = div.find('div', class_='sc_listingTilePrice')\n",
        "      # if price_div:\n",
        "      #     price_spans = price_div.find_all('span')\n",
        "      #     if len(price_spans) > 1:\n",
        "      #         from_price = price_spans[1].text.strip()\n",
        "      #         to_price = price_spans[3].text.strip()\n",
        "      #         price = f\"From {from_price} to {to_price}\"\n",
        "      #     else:\n",
        "      #         price = price_spans[0].text.strip()\n",
        "      # else:\n",
        "      #     price = None\n",
        "      # Extract price and rent term\n",
        "      price_div = div.find('div', class_='sc_listingTilePrice')\n",
        "      if price_div:\n",
        "          price_span = price_div.find('span')\n",
        "          if price_span:\n",
        "              price = price_span.text.strip()\n",
        "          else:\n",
        "              price = None\n",
        "\n",
        "          rent_term_span = div.find('span', class_='sc_listingTilePriceRentTermDescription')\n",
        "          if rent_term_span:\n",
        "              rent_term = rent_term_span.text.strip()\n",
        "          else:\n",
        "              rent_term = None\n",
        "      else:\n",
        "          price = None\n",
        "          rent_term = None\n",
        "\n",
        "\n",
        "      address = div.find('div', class_='sc_listingTileAddress').text.strip()\n",
        "      bed_img = div.find('img', class_='property24generic_icon_beds')\n",
        "      baths_img = div.find('img', class_='property24generic_icon_baths')\n",
        "      parking_img = div.find('img', class_='property24generic_icon_parking')\n",
        "\n",
        "      beds = bed_img.find_next('span').get_text() if bed_img else \"\"\n",
        "      baths = baths_img.find_next('span').get_text() if baths_img else \"\"\n",
        "      parking = parking_img.find_next('span').get_text() if parking_img else \"\"\n",
        "\n",
        "      floor_unit = \"\"\n",
        "      erf_unit = \"\"\n",
        "      floor_size = \"\"\n",
        "      erf_size = \"\"\n",
        "\n",
        "      floor_size_span = div.find('span', class_='sc_erfSize')\n",
        "      if floor_size_span:\n",
        "          text = floor_size_span.get_text()\n",
        "          if 'Floor Size' in text:\n",
        "              floor_size = floor_size_span.find('span').get_text().strip()\n",
        "              floor_unit = floor_size_span.contents[-1].strip()\n",
        "          elif 'Erf Size' in text:\n",
        "              erf_size = floor_size_span.find('span').get_text().strip()\n",
        "              erf_unit = floor_size_span.contents[-1].strip()\n",
        "\n",
        "      property_data = {\n",
        "        'Property URL': propertyurl,\n",
        "        'Title': title,\n",
        "        'Type' : \"To Rent\",\n",
        "        'Price': price,\n",
        "        'Payment Interval': rent_term,\n",
        "        'Address': address,\n",
        "        'Description': description,\n",
        "        'Bedrooms': beds,\n",
        "        'Bathrooms': baths,\n",
        "        'Parking spaces': parking,\n",
        "        'Floor Size': floor_size + ' ' + floor_unit,\n",
        "        'Erf Size': erf_size + ' ' + erf_unit,\n",
        "    }\n",
        "\n",
        "      df = pd.concat([df, pd.DataFrame([property_data])], ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "u9pWyytIudbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(30)"
      ],
      "metadata": {
        "id": "jMZ84YMfudxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save CSV File of Property24 Kenya Properties"
      ],
      "metadata": {
        "id": "1kTv_Svsx5Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "df.to_csv('Property24Kenya.csv', index=False)\n",
        "files.download('Property24Kenya.csv')"
      ],
      "metadata": {
        "id": "6ZuAZQM2ggbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Schedule to run the scraper every 10 hours\n"
      ],
      "metadata": {
        "id": "0BdqPkEWt8gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "# Define your scraping functions\n",
        "def scrape_data_for_sale(for_sale_url, df):\n",
        "    # Your scraping logic for property for sale\n",
        "    # ...\n",
        "\n",
        "def scrape_data_for_rent(to_rent_url, df):\n",
        "    # Your scraping logic for property to rent\n",
        "    # ...\n",
        "\n",
        "# Set initial for_sale_url and to_rent_url\n",
        "for_sale_url = 'https://www.property24.co.ke/property-for-sale?provinceids=83,96,93,76,79,66,101,80,76,86&cityids=1890,1848,1847,1850,1868,1899,1901,2149'\n",
        "to_rent_url = 'https://www.property24.co.ke/property-to-rent?provinceids=83,96,93,76,79,66,101,80,76,86&cityids=1890,1848,1847,1850,1868,1899,1901,2149'\n",
        "\n",
        "# Initialize an empty dataframe\n",
        "data = {'Property URL': [], 'Title': [], 'Type': [], 'Price': [], 'Address': [], 'Description': [],\n",
        "        'Bedrooms': [], 'Bathrooms': [], 'Parking spaces': [],\n",
        "        'Floor Size': [], 'Erf Size': [], }\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set the interval (in seconds)\n",
        "interval_seconds = 10 * 60 * 60  # 10 hours\n",
        "\n",
        "# Run the script in a loop\n",
        "while True:\n",
        "    # Call your scraping functions\n",
        "    scrape_data_for_sale(for_sale_url, df)\n",
        "    scrape_data_for_rent(to_rent_url, df)\n",
        "\n",
        "    # Print the dataframe\n",
        "    print(df)\n",
        "\n",
        "    # Save the dataframe to CSV\n",
        "    df.to_csv('Property24Kenya.csv', index=False)\n",
        "\n",
        "    # Wait for the specified interval before the next iteration\n",
        "    time.sleep(interval_seconds)\n"
      ],
      "metadata": {
        "id": "VuW8IMLgggjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Deb4Cv-YggoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1Mky3hgggr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WlcYjmY6ggvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M0CfZjFPggy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QaHwNAwhgg2N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}